{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 일반 다층 퍼셉트론 모델(MLP)로 이미지 데이터 분류하기\n",
    "\n",
    "이번 실습에서는 테스트용 MNIST 데이터를 96% 이상의 정확도로 분류하는 **다층 퍼셉트론 모델(MLP)**을 만들고 학습시켜보겠습니다.\n",
    "\n",
    "이번 실습에선 10개 클래스를 가진 28x28 크기의 단순 숫자 이미지만을 모델에 학습시켰지만, 1000개 클래스를 가진 224x224 크기의 각종 사물, 동물 이미지를 이 모델에 학습시켜도 좋은 성능이 나올까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 일반 다층 퍼셉트론 모델(MLP)로 이미지 데이터 분류를 위한 함수/라이브러리\n",
    "\n",
    "- tf.keras.layers.Flatten()\n",
    "\n",
    "2차원 데이터를 1차원 데이터로 평평하게 만들어줍니다.\n",
    "\n",
    "- tf.keras.layers.Dense(node, activation)\n",
    "\n",
    " - node : 노드(뉴런) 개수\n",
    " - activation : 활성화 함수\n",
    "\n",
    "- from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "label을 클래스화 할 수 있는 원-핫 인코딩을 해주는 모듈입니다.\n",
    "\n",
    "- label = to_categorical(label, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 지시사항\n",
    "1. MNIST 데이터 셋을 전처리하는 preprocess() 함수를 완성합니다.\n",
    "2. 다층 퍼셉트론(MLP) 모델을 생성합니다. 입력층과 출력층은 다음의 지시사항을 따르고, 히든층들은 레이어 내부의 변수들을 다양하게 조정하면서 자유롭게 쌓아보세요.\n",
    "    - 입력층 (Input layer)\n",
    "    28x28 크기의 2차원 이미지 데이터를 1차원 데이터로 평평하게 만듭니다.\n",
    "    - 출력층 (Output layer)\n",
    "    10개 클래스에 대한 확률을 출력합니다. 이전 장의 실습을 떠올려보면서 어떤 활성화 함수를 써야 할 지 생각해보세요.\n",
    "3. 모델을 불러온 후 학습시키고 테스트 데이터에 대해 평가합니다. 그리고 모델의 성능을 확인해 test_acc 값이 0.96을 넘도록 해보세요.\n",
    "\n",
    "모델에 대해 손실 함수(loss function), 최적화(optimize) 알고리즘, 평가 방법(metrics)을 자유롭게 설정해보세요. 이전 장의 실습을 참고해도 좋습니다.\n",
    "\n",
    "## Tips!\n",
    "- 모델 학습(fit) 과정에서 verbose 변수를 활용하면 모델의 학습 과정 기록을 간단하게 표현할 수 있습니다. 이후 실습에서도 이를 활용해서 학습 과정 기록을 확인하세요.\n",
    "\n",
    "    - verbose = 0: 기록을 나타내지 않음.\n",
    "    - verbose = 1: 진행 바 형태의 학습 과정 기록을 나타냄.\n",
    "    - verbose = 2: epoch 당 1줄의 학습 과정 기록을 나타냄.\n",
    "- MLP 모델에서는 2차원 이미지 데이터의 픽셀값을 1차원으로 쭉 피고, 그것을 Dense 레이어에 넣어서 모델을 학습시킵니다. 즉, 이 모델은 이미지의 특성을 학습하는 게 아니라 단순 Numpy 배열의 값만을 학습합니다. 그러면 이미지가 가지고 있는 특성은 의미가 없어지는 걸까요?\n",
    "\n",
    "- 지금까지 실습에서 MNIST 데이터셋을 불러온 후 항상 255로 나누었습니다.\n",
    "이를 **이미지 정규화** 라고 하며 정규화를 하는 이유는 모델이 0-255 사이의 값을 학습하는 것보다 0~1 사이로 정규화된 값을 학습할 때 학습 속도가 더 빨라지고 최적화가 잘 된다는 것이 알려져 있기 때문입니다.\n",
    "\n",
    "- 지금까지의 실습에선 0-9 사이 값인 label을 그대로 사용해서 MNIST 숫자 분류를 진행했습니다. 즉, 실제값을 그대로 클래스로 이용해서 모델을 평가하고 테스트했습니다.\n",
    "하지만 이 경우 자칫 잘못하면 0-9 사이에 ‘순위’가 매겨져 0은 0으로 label이 매겨졌기에 별로 안 중요하고, 9는 9로 label이 매겨졌기에 아주 중요하다고 모델이 판단할 수 있습니다. 하지만 대부분의 다중 클래스 분류 문제에선 각 클래스의 관계가 균등합니다.\n",
    "이를 해결할 수 있는 방법으로 **‘원-핫 인코딩‘** 이 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 4s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 136,074\n",
      "Trainable params: 136,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/6\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 1.1771 - accuracy: 0.6765 - val_loss: 0.2684 - val_accuracy: 0.9221\n",
      "Epoch 2/6\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2625 - accuracy: 0.9240 - val_loss: 0.1990 - val_accuracy: 0.9406\n",
      "Epoch 3/6\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1826 - accuracy: 0.9470 - val_loss: 0.1584 - val_accuracy: 0.9529\n",
      "Epoch 4/6\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1487 - accuracy: 0.9555 - val_loss: 0.1405 - val_accuracy: 0.9570\n",
      "Epoch 5/6\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1202 - accuracy: 0.9652 - val_loss: 0.1187 - val_accuracy: 0.9636\n",
      "Epoch 6/6\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1012 - accuracy: 0.9698 - val_loss: 0.1017 - val_accuracy: 0.9691\n",
      "313/313 - 0s - loss: 0.1017 - accuracy: 0.9691\n",
      "\n",
      "Test Loss : 0.1017 | Test Accuracy : 0.9690999984741211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측한 Test Data 클래스 :  [7 2 1 ... 4 5 6]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Visulaize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a3209c67fbe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-a3209c67fbe5>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'예측한 Test Data 클래스 : '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m     \u001b[0mVisulaize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MLP'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Visulaize' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "#MNIST는 손으로 쓴 숫자\n",
    "\n",
    "# 동일한 실행 결과 확인을 위한 코드입니다.\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "'''\n",
    "지시사항 1번\n",
    "   MNIST 데이테 셋을 전처리하는 'preprocess' 함수를 완성합니다.\n",
    "   \n",
    "   전처리하는데 시간을 더 많이 쓰게 되기도 한다. \n",
    "\n",
    "   Step01. MNIST 데이터 이미지를 0~1 사이 값으로 정규화해줍니다.\n",
    "           원본은 0~255 사이의 값입니다.\n",
    "           \n",
    "   Step02. 0~9 사이 값인 label을 클래스화 하기 위해 \n",
    "           원-핫 인코딩을 진행합니다.\n",
    "\n",
    "'''\n",
    "\n",
    "def preprocess():\n",
    "    \n",
    "    # MNIST 데이터 세트를 불러옵니다.\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    \n",
    "    # MNIST 데이터 세트를 Train set과 Test set으로 나누어 줍니다.\n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()    \n",
    "    \n",
    "    train_images = train_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "    \n",
    "    #test_images 도 동일하게 전처리 해줘야 한다. \n",
    "    \n",
    "    train_labels = to_categorical(train_labels, 10)\n",
    "    test_labels = to_categorical(test_labels, 10)  \n",
    "    \n",
    "    return train_images, test_images, train_labels, test_labels\n",
    "\n",
    "\n",
    "'''\n",
    "지시사항 2번\n",
    "   다층 퍼셉트론(MLP) 모델을 생성합니다.\n",
    "\n",
    "'''\n",
    "def MLP():\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape= (28, 28)))\n",
    "    model.add(tf.keras.layers.Dense(units=128, activation='sigmoid'))\n",
    "    model.add(tf.keras.layers.Dense(units=256, activation='sigmoid'))\n",
    "    \n",
    "    # 모델 정의 마지막 레이어\n",
    "    model.add(tf.keras.layers.Dense(units=10,  activation='softmax')) # node 말고 숫자만\n",
    "    #unit 대신 node 써도 되고, 숫자만 써도 됨\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "'''\n",
    "지시사항 3번\n",
    "   모델을 불러온 후 학습시키고 테스트 데이터에 대해 평가합니다.\n",
    "\n",
    "   Step01. MLP 함수를 통해 모델을 불러옵니다.\n",
    "   \n",
    "   Step02. 모델의 손실 함수, 최적화 알고리즘, 평가 방법을 설정합니다.\n",
    "   \n",
    "   Step03. 모델의 구조를 확인하는 코드를 작성합니다.\n",
    "   \n",
    "   Step04. 모델을 학습시킵니다. 검증용 데이터도 설정하세요.\n",
    "           'epochs'와 'batch_size'도 자유롭게 설정하세요.\n",
    "              \n",
    "   Step05. 모델을 테스트하고 손실(loss)값과 \n",
    "           Test Accuracy 값 및 예측 클래스, \n",
    "           손실 함수값 그래프를 출력합니다. \n",
    "           \n",
    "           모델의 성능을 확인해보고,\n",
    "           목표값을 달성해보세요.\n",
    "'''\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # 데이터를 불러옵니다.\n",
    "    train_images, test_images, train_labels, test_labels = preprocess()\n",
    "    \n",
    "    # 지시사항 2에서 설정한 모델을 불러옵니다.\n",
    "    model = MLP()\n",
    "        \n",
    "    # 모델의 구조를 확인합니다.\n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "    # 컴파일러를 설정합니다.\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    \n",
    "    # fit 함수를 사용하여 모델을 학습합니다.\n",
    "    # 학습 수행 시 정보는 history에 저장합니다.\n",
    "    history = model.fit(train_images, train_labels, epochs = 6, batch_size = 128, verbose=1, validation_data = (test_images, test_labels) )\n",
    "    \n",
    "    # evaluate 함수를 사용하여 테스트 데이터의 결과값을 저장합니다.\n",
    "    loss, test_acc = model.evaluate(test_images, test_labels, verbose = 2)\n",
    "    \n",
    "    print('\\nTest Loss : {:.4f} | Test Accuracy : {}'.format(loss, test_acc))\n",
    "    print('예측한 Test Data 클래스 : ',model.predict_classes(test_images))\n",
    "    \n",
    "    Visulaize([('MLP', history)], 'loss')\n",
    "    \n",
    "    return test_acc\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from visual import *\n",
    "\n",
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# 동일한 실행 결과 확인을 위한 코드입니다.\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "'''\n",
    "지시사항 1번\n",
    "   MNIST 데이테 셋을 전처리하는 'preprocess' 함수를 완성합니다.\n",
    "\n",
    "   Step01. MNIST 데이터 이미지를 0~1 사이 값으로 정규화해줍니다.\n",
    "           원본은 0~255 사이의 값입니다.\n",
    "           \n",
    "   Step02. 0~9 사이 값인 label을 클래스화 하기 위해 \n",
    "           원-핫 인코딩을 진행합니다.\n",
    "\n",
    "'''\n",
    "\n",
    "def preprocess():\n",
    "    \n",
    "    # MNIST 데이터 세트를 불러옵니다.\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    \n",
    "    # MNIST 데이터 세트를 Train set과 Test set으로 나누어 줍니다.\n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()    \n",
    "    \n",
    "    train_images = train_images / 255.\n",
    "    test_images = test_images / 255.\n",
    "    \n",
    "    train_labels = to_categorical(train_labels, 10)\n",
    "    test_labels = to_categorical(test_labels, 10)  \n",
    "    \n",
    "    return train_images, test_images, train_labels, test_labels\n",
    "\n",
    "\n",
    "'''\n",
    "지시사항 2번\n",
    "   다층 퍼셉트론(MLP) 모델을 생성합니다.\n",
    "\n",
    "'''\n",
    "def MLP():\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    ## 시작하는 layer에 input_shape을 넣을 수도 있지만 Input Layer를 추가 하는 것도 가능\n",
    "    model.add(tf.keras.layers.Input(shape=(28, 28)))    # Input Layer 추가\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=16, activation='sigmoid'))\n",
    "    # 마지막 layer\n",
    "    model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "'''\n",
    "지시사항 3번\n",
    "   모델을 불러온 후 학습시키고 테스트 데이터에 대해 평가합니다.\n",
    "\n",
    "   Step01. MLP 함수를 통해 모델을 불러옵니다.\n",
    "   \n",
    "   Step02. 모델의 손실 함수, 최적화 알고리즘, 평가 방법을 설정합니다.\n",
    "   \n",
    "   Step03. 모델의 구조를 확인하는 코드를 작성합니다.\n",
    "   \n",
    "   Step04. 모델을 학습시킵니다. 검증용 데이터도 설정하세요.\n",
    "           'epochs'와 'batch_size'도 자유롭게 설정하세요.\n",
    "              \n",
    "   Step05. 모델을 테스트하고 손실(loss)값과 \n",
    "           Test Accuracy 값 및 예측 클래스, \n",
    "           손실 함수값 그래프를 출력합니다. \n",
    "           \n",
    "           모델의 성능을 확인해보고,\n",
    "           목표값을 달성해보세요.\n",
    "'''\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # 데이터를 불러옵니다.\n",
    "    train_images, test_images, train_labels, test_labels = preprocess()\n",
    "    \n",
    "    # 지시사항 2에서 설정한 모델을 불러옵니다.\n",
    "    model = MLP()\n",
    "    \n",
    "    # 모델의 구조를 확인합니다.\n",
    "    model.summary()\n",
    "    \n",
    "    # 컴파일러를 설정합니다.\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    \n",
    "    # fit 함수를 사용하여 모델을 학습합니다.\n",
    "    # 학습 수행 시 정보는 history에 저장합니다.\n",
    "    history = model.fit(train_images, train_labels, epochs=10, batch_size=128, \n",
    "                        validation_data=(test_images, test_labels), verbose=2)\n",
    "    \n",
    "    # evaluate 함수를 사용하여 테스트 데이터의 결과값을 저장합니다.\n",
    "    loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "    \n",
    "    print('\\nTest Loss : {:.4f} | Test Accuracy : {}'.format(loss, test_acc))\n",
    "    print('예측한 Test Data 클래스 : ',model.predict_classes(test_images))\n",
    "    \n",
    "    Visulaize([('MLP', history)], 'loss')\n",
    "    \n",
    "    return test_acc\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 데이터 확인하기\n",
    "이번 실습에서는 Numpy, PIL, tensorflow.keras 등을 이용하여 이미지를 Numpy 배열로 바꿔보고, 이를 통해 이미지가 어떻게 이루어졌는지 확인해보겠습니다.\n",
    "\n",
    "실습에서 활용할 이미지 데이터는 data 폴더의 images 폴더 안에 10장의 이미지 중 하나의 이미지에 대해 실습을 진행하겠습니다.\n",
    "\n",
    "이미지 데이터를 확인하기 위한 라이브러리/함수\n",
    "\n",
    "- import PIL: \n",
    "이미지를 불러오고 처리하기 위한 라이브러리입니다.\n",
    "\n",
    "- PIL.Image.open(path): \n",
    "이미지를 불러 옵니다.\n",
    "\n",
    "- PIL.Image.resize(width,height): \n",
    "이미지의 크기를 조정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 지시사항\n",
    "1. PIL.Image를 이용하여 이름(경로+이름)을 바탕으로 이미지를 불러오고, 이를 리스트 images에 추가하세요.\n",
    "2. 이미지의 사이즈를 조정하고 이를 Numpy 배열로 변환하세요.\n",
    "3. 지금까지 완성한 함수를 이용해 main 함수를 완성하세요.\n",
    "\n",
    "## Tips!\n",
    "- 원본 이미지의 크기와 resize 후의 이미지 크기(1-3, 2-3에 해당)를 비교해보세요. 그리고 원본 이미지와 resize된 이미지(1-1, 2-1에 해당)와 비교해보세요.\n",
    "- 이미지 1장에 해당하는 Numpy 배열의 크기(1-3, 2-3에 해당)와 이미지 10장에 해당하는 Numpy 배열의 크기(3에 해당)를 확인해보세요. 이미지의 수, 가로 길이, 세로 길이, RGB 차원 수는 Numpy 배열에서 차이를 확인해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import PIL\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "# 이미지 목록을 불러오는 함수입니다.\n",
    "\n",
    "def load_data(path):\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "'''\n",
    "지시사항 1번\n",
    "   PIL.Image를 이용하여 \n",
    "   이름(경로+이름)을 바탕으로 이미지를 불러오고,\n",
    "   이를 리스트 'images'에 추가하는 함수를 완성합니다.\n",
    "   main 함수에서 'path'와 'names' 변수를 확인해보세요.\n",
    "'''\n",
    "\n",
    "def load_images(path, names):\n",
    "    \n",
    "    images=[]\n",
    "    for fname in names:\n",
    "        file_path = path + fname\n",
    "        im = PIL.Image.open(file_path)\n",
    "        images.append(im)\n",
    "    \n",
    "    \n",
    "    return images\n",
    "\n",
    "'''\n",
    "지시사항 2번\n",
    "   이미지의 사이즈를 main 함수에 있는 'IMG_SIZE'로 \n",
    "   조정하고, 이를 Numpy 배열로 변환하는 함수를 완성합니다.\n",
    "'''\n",
    "\n",
    "def images2numpy(images, size):\n",
    "    #image는 list 형태, 이미지를 하나씩 가져와서 resize\n",
    "    #w, h = size\n",
    "    output = []\n",
    "    \n",
    "    for im in images:\n",
    "        im_resize = im.resize(size)\n",
    "        im_npy = np.array(im_resize) #im_resize를 넘파이로 변환\n",
    "        output.append(im_npy)\n",
    "    output = np.array(output)\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "# 이미지에 대한 정보를 나타내주는 함수입니다.\n",
    "\n",
    "def sampleVisualize(np_images):\n",
    "\n",
    "    fileName = \"./data/images/1000092795.jpg\"\n",
    "    ndarray = img.imread(fileName)\n",
    "    \n",
    "    plt.imshow(ndarray)\n",
    "    plt.show()    \n",
    "    plt.savefig(\"plot.png\")\n",
    "    \n",
    "    print(\"\\n1-1. 'fileName' 이미지(원본): \")\n",
    "    elice_utils.send_image(\"plot.png\")\n",
    "    \n",
    "    print('\\n1-2. Numpy array로 변환된 원본 이미지:', ndarray)\n",
    "    print('\\n1-3. Numpy array로 변환된 원본 이미지의 크기:', np.array(ndarray).shape)\n",
    "    \n",
    "    plt.imshow(np_images[0])\n",
    "    plt.show()\n",
    "    plt.savefig(\"plot_re.png\")\n",
    "    \n",
    "    print(\"\\n2-1. 'fileName' 이미지(resize 후): \")\n",
    "    elice_utils.send_image(\"plot_re.png\")\n",
    "    \n",
    "    print('\\n2-2. Numpy array로 변환된 resize 후 이미지:', np_images[0])\n",
    "    print('\\n2-3. Numpy array로 변환된 resize 후 이미지 크기:', np.array(np_images[0]).shape)    \n",
    "    \n",
    "    print('\\n3. Numpy array로 변환된 resize 후 이미지 10장의 크기:', np.array(np_images).shape)\n",
    "\n",
    "'''\n",
    "지시사항 3번\n",
    "   main 함수를 완성하세요.\n",
    "   \n",
    "   Step01. 이미지를 불러오는 함수를 이용해 \n",
    "           'images'를 정의합니다.\n",
    "   \n",
    "   Step02. 이미지를 Numpy 배열로 바꾸는 함수를 이용해\n",
    "           'np_images'를 정의합니다.\n",
    "'''\n",
    "\n",
    "def main():\n",
    "    \n",
    "    CSV_PATH = \"./data/data.csv\"\n",
    "    IMG_PATH = \"./data/images/\"\n",
    "    IMG_SIZE = (300,300)\n",
    "    MAX_LEN = 30\n",
    "    BATCH_SIZE = 2\n",
    "    \n",
    "    name_caption = load_data(CSV_PATH)\n",
    "    names = name_caption['file_name']\n",
    "    \n",
    "    print(names)\n",
    "    images = load_images(path = IMG_PATH, names = names)\n",
    "    np_images = images2numpy(images, size = IMG_SIZE)\n",
    "    \n",
    "    sampleVisualize(np_images)\n",
    "    \n",
    "    return images, np_images\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Layer\n",
    "실습을 통해 Convolution Layer를 구성하는 방법에 대해 알아보겠습니다.\n",
    "\n",
    "### Tensorflow에 합성곱 신경망 (CNN)을 구성하기 위한 함수/라이브러리\n",
    "\n",
    "- keras.layers.Conv2D(filters, kernal_size, strides, padding, activation)(image)\n",
    "    - filgers : output filter의 개수\n",
    "    - kernel : Convolution을 위한 kernel\n",
    "    - stride : 정수 및 튜플, 리스트 형태의 값 ex) [2,2]\n",
    "    - padding : SAME / VALID\n",
    "    - activation : 활성화 함수\n",
    "    - image : 입력 영상\n",
    "\n",
    "## 지시사항\n",
    "아래의 내용을 참고하여 **keras.layers.Conv2D()** 를 완성하세요.\n",
    "\n",
    "매개변수\t값\n",
    "\n",
    "filter   \t1\n",
    "\n",
    "kernel_size\t2\n",
    "\n",
    "padding\t  VALID\n",
    "\n",
    "kernel_initializer\tkernel_init\n",
    "\n",
    "## Tips!\n",
    "- Stride은 이미지 픽셀을 건너뛰며 합성곱 연산을 진행합니다. 이를 통해 이미지의 차원을 줄일 수 있습니다.\n",
    "\n",
    "    - $ Output size = {{(Image - Kernel) / stride} +1}$ \n",
    "\n",
    "- **Padding** 은 Kernel이 이미지 경계를 벗어나지 않도록 하거나 경우에 따라 경계를 벗어나는 경우 모자라는 부분을 채워줍니다.\n",
    "    - SAME : 합성곱 입력과 출력을 같게 합니다.\n",
    "    - VALID : Kernel이 이미지 경계를 벗어나지 않도록 합니다.\n",
    "- 관련 링크\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
    "https://github.com/deeplearningzerotoall/TensorFlow/blob/master/lab-11-0-cnn-basics-keras-eager.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "def Visualize(image, x, y):\n",
    "    plt.imshow(image.reshape(x,y), cmap ='Greys')\n",
    "    plt.savefig('plot.png')\n",
    "    elice_utils.send_image(\"plot.png\")\n",
    "    \n",
    "\n",
    "# 임의의 3 x 3 x 1 영상을 하나 만들어줍니다.\n",
    "image = np.array([[[[1],[2],[3]],\n",
    "                   [[4],[5],[6]],\n",
    "                   [[7],[8],[9]]]], dtype = np.float32)\n",
    "\n",
    "# 합성곱 연산을 위해 임의의 2 x 2 x 1 커널을 하나 만들어줍니다.\n",
    "kernel = np.array([[[[1.]],[[1.]]],\n",
    "                      [[[1.]],[[1.]]]])\n",
    "\n",
    "\n",
    "# 이미지 Shape 출력 : (num of image, width, height, channel)\n",
    "print('Image shape : ', image.shape)\n",
    "# 커널 Shape 출력 : (width, height, channel, num of kernel)\n",
    "print('Kernel shape : ', kernel.shape)\n",
    "# tf.nn.conv2d에 넣기 위해 이미지와 커널의 Shape을 위와 같이 만들었습니다.\n",
    "\n",
    "\n",
    "# Gray 이미지 출력\n",
    "Visualize(image, 3 ,3)\n",
    "\n",
    "kernel_init = tf.constant_initializer(kernel)\n",
    "# Convolution Layer 선언\n",
    "'''\n",
    "지시사항1번 \n",
    "   keras.layers.Conv2D()를 완성하세요.\n",
    "'''\n",
    "conv2d = keras.layers.Conv2D(filters= 1, kernel_size= 2, padding= 'VALID', kernel_initializer= kernel_init)(image)\n",
    "Visualize(conv2d.numpy(), 2,2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max Pooling Layer\n",
    "전체적인 CNN (Convolution Neural Network)를 만들기 위해서는 몇가지 추가 기능이 더 필요합니다.\n",
    "\n",
    "대표적으로 **Max Pooling Layer** 는 일반적으로 Convolution Layer 뒤에 붙여 Conv layer의 결과(Feature Map)를 축소시키는데 사용합니다.\n",
    "\n",
    "M x N 크기의 Pooling Filter를 적용하고, 그 안에서 가장 큰 값을 추출합니다.\n",
    "\n",
    "이러한 작업을 통해 **Feature map의 사이즈를 줄여 연산량을 줄일 수 있으며, Feature의 개수가 줄어들기 때문에 Overfitting 방지**  할 수 있습니다.\n",
    "\n",
    "### MaxPooling을 위한 함수/라이브러리\n",
    "\n",
    "- keras.layers.MaxPool2D(pool_size, strides, padding)\n",
    "- pool_size : Pooling filter의 크기\n",
    "- strides : Filter를 적용할 간격\n",
    "- padding : SAME or VALID\n",
    "이번 실습에서는 Max Pooling Layer을 알아보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "def Visualize(image, x, y):\n",
    "    plt.imshow(image.reshape(x,y), cmap ='Greys')\n",
    "    plt.savefig('plot.png')\n",
    "    elice_utils.send_image(\"plot.png\")\n",
    "    \n",
    "# 임의의 3 x 3 x 1 영상을 하나 만들어줍니다.\n",
    "image = tf.constant([[[[1],[2],[3],[4]],\n",
    "                   [[4],[5],[6],[7]],\n",
    "                   [[7],[8],[9],[10]],\n",
    "                   [[3],[5],[7],[9]]]], dtype = np.float32)\n",
    "\n",
    "'''\n",
    "지시사항 1번\n",
    "Max Pooling Layer를 선언하세요.\n",
    "''' \n",
    "pool = keras.layers.MaxPool2D(pool_size=2, strides=2, padding='VALID')(image)\n",
    "#padding = 'VALID'는 zero padding 이다.\n",
    "\n",
    "print(pool.shape)\n",
    "print(pool.numpy())\n",
    "\n",
    "# 원본 영상과 Max Pooling 후 영상을 출력합니다..\n",
    "Visualize(image.numpy(), 4,4)\n",
    "Visualize(pool.numpy(), 2,2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras로 CNN 구현하기\n",
    "이번 실습에서는 테스트용 MNIST 데이터를 95% 이상의 정확도로 분류하는 CNN 모델을 만들고 학습 시켜보겠습니다.\n",
    "\n",
    "## Keras로 CNN을 구현하기 위한 함수/라이브러리\n",
    "\n",
    "- tf.keras.layers.Conv2D(filters, kernel_size, activation, padding)\n",
    "\n",
    "입력 이미지의 특징, 즉 처리할 특징 맵(map)을 추출하는 레이어입니다.\n",
    "\n",
    "    - filters : 필터(커널) 개수\n",
    "    - kernel_size : 필터(커널)의 크기\n",
    "    - activation : 활성화 함수\n",
    "    - padding : 이미지가 필터를 거칠 때 그 크기가 줄어드는 것을 방지하기 위해서 가장자리에 0의 값을 가지는 픽셀을 넣을 것인지 말 것인지를 결정하는 변수. SAME 또는 VALID\n",
    "\n",
    "- tf.keras.layers.MaxPool2D(padding)\n",
    "\n",
    "처리할 특징 맵(map)의 크기를 줄여주는 레이어입니다.\n",
    "\n",
    "    - padding : SAME 또는 VALID\n",
    "\n",
    "- tf.keras.layers.Flatten()\n",
    "\n",
    "Convolution layer 또는 MaxPooling layer의 결과는 N차원의 텐서 형태입니다. 이를 1차원으로 평평하게 만들어줍니다.\n",
    "\n",
    "- tf.keras.layers.Dense(node, activation)\n",
    "    - node : 노드(뉴런) 개수\n",
    "    - activation : 활성화 함수\n",
    "\n",
    "- np.expand_dims(data, axis)\n",
    "\n",
    "Numpy 배열 데이터에서 마지막 축(axis)에 해당하는 곳에 차원 하나를 추가할 수 있는 코드입니다.\n",
    "\n",
    "## 지시시항\n",
    "1. MNIST 데이터 셋을 전처리하는 **preprocess()** 함수를 완성합니다.\n",
    "2. CNN 모델을 생성합니다. 입력층과 출력층은 다음의 지시사항을 따르고, 히든층들은 위 설명의 **CNN in Keras** 를 참고해 자유롭게 쌓아보세요. 단, Convolution 레이어 - MaxPooling 레이어 쌍이 최소 3개 이상이 되도록 하세요.\n",
    "\n",
    "    - **입력층 (Input layer):**  \n",
    "    CNN 모델에서는 입력층에서 Flatten 레이어를 이용해 데이터를 1차원으로 펴줄 필요 없이 Convolution layer를 입력층으로 쓰고, 내부 변수인 input_shape를 조정함으로써 2차원 데이터를 바로 입력으로 넣을 수 있습니다.\n",
    "    이전 실습과 이번 실습 1번을 참고해서 input_shape이 어떻게 되야할 지 생각해서 입력층을 작성해보세요.\n",
    "\n",
    "    - **출력층 (Output layer):**  \n",
    "    10개 클래스에 대한 확률을 출력합니다. 이전 실습과 동일합니다.\n",
    "\n",
    "3. 모델을 불러온 후 학습시키고 테스트 데이터에 대해 평가합니다.\n",
    "\n",
    "모델에 대해 손실 함수(loss function), 최적화(optimize) 알고리즘, 평가 방법(metrics)은 이전 실습과 동일하게 설정하세요.\n",
    "\n",
    "모델의 성능을 확인해 test_acc 값이 0.95을 넘도록 해보세요.\n",
    "\n",
    "## Tips!\n",
    "- MNIST 데이터는 이미지 데이터이지만 가로 길이와 세로 길이만 존재하는 2차원 데이터입니다. CNN 모델은 채널(RGB 혹은 흑백)까지 고려한 3차원 데이터를 입력으로 받기에 채널 차원을 추가해 데이터의 모양(shape)을 바꿔줍니다. 결과는 아래와 같습니다.\n",
    "\n",
    "[데이터 수, 가로 길이, 세로 길이] -> [데이터 수, 가로 길이, 세로 길이, 채널 수]\n",
    "- 이전 실습의 MLP 모델과 이번 실습의 CNN 모델엔 어떤 차이가 있을지 생각해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from visual import *\n",
    "from plotter import *\n",
    "\n",
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# 동일한 실행 결과 확인을 위한 코드입니다.\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "'''\n",
    "지시사항 1번\n",
    "MNIST 데이테 셋을 전처리하는 'preprocess' 함수를 완성합니다.\n",
    "   \n",
    "   Step01과 Step03은 이전 실습과 동일한 코드를 사용할 수 있습니다.\n",
    "\n",
    "   Step01. MNIST 데이터 이미지를 0~1 사이 값으로 정규화해줍니다.\n",
    "           원본은 0~255 사이의 값입니다.\n",
    "           \n",
    "   Step02. MNIST 데이터의 채널 차원을 추가해줍니다.\n",
    "           \n",
    "   Step03. 0~9 사이 값인 레이블을 클래스화 하기 위해 원-핫 인코딩을 진행합니다.\n",
    "   \n",
    "'''\n",
    "\n",
    "def preprocess():\n",
    "    \n",
    "    # MNIST 데이터 세트를 불러옵니다.\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    \n",
    "    # MNIST 데이터 세트를 Train set과 Test set으로 나누어 줍니다.\n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()    \n",
    "    \n",
    "    # Train 데이터 5000개와 Test 데이터 1000개를 사용합니다.\n",
    "    train_images, train_labels = train_images[:5000], train_labels[:5000]\n",
    "    test_images, test_labels = test_images[:1000], test_labels[:1000]\n",
    "    \n",
    "    train_images = train_images / 255\n",
    "    test_images = test_images / 255\n",
    "    \n",
    "    print(train_images.shape, test_images.shape)\n",
    "    \n",
    "    train_images = np.expand_dims(train_images, axis=-1)\n",
    "    test_images = np.expand_dims(test_images, axis= -1)\n",
    "    \n",
    "    train_labels = to_categorical(train_labels, 10)\n",
    "    test_labels = to_categorical(test_labels, 10)\n",
    "    \n",
    "    return train_images, test_images, train_labels, test_labels\n",
    "\n",
    "'''\n",
    "지시사항 2번\n",
    "CNN 모델을 생성합니다.\n",
    "Convolution\n",
    "'''\n",
    "def CNN():\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(28,28,1)))\n",
    "    \n",
    "    #Conv + pool 3번 이상 정도 하기, filters 수 갈수록 늘려주면 정확도 높아짐\n",
    "    model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='sigmoid', padding='SAME'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(2, padding='VALID'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='SAME'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(2, padding='VALID'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='SAME'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(2, padding='VALID'))\n",
    "    \n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    \n",
    "    #MLP -> Dense, 학습 파라미터\n",
    "    model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "    \n",
    "'''\n",
    "지시사항 3번\n",
    "모델을 불러온 후 학습시키고 테스트 데이터에 대해 평가합니다.\n",
    "\n",
    "   Step01. CNN 함수를 통해 모델을 불러옵니다.\n",
    "   \n",
    "   Step02. 모델의 손실 함수, 최적화 알고리즘, 평가 방법을 설정합니다.\n",
    "   \n",
    "   Step03. 모델의 구조를 확인하는 코드를 작성합니다.\n",
    "   \n",
    "   Step04. 모델을 학습시킵니다. 검증용 데이터도 설정하세요.\n",
    "           'epochs'와 'batch_size'도 자유롭게 설정하세요.\n",
    "           단, 'epochs'이 클수록, 'batch_size'는 작을수록 학습 속도가 느립니다.\n",
    "   \n",
    "   Step05. 모델을 테스트하고 손실(loss)값과 Test Accuracy 값 및 예측 클래스, \n",
    "           손실 함수값 그래프를 출력합니다. 모델의 성능을 확인해보고,\n",
    "           목표값을 달성해보세요.\n",
    "'''\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # 데이터를 불러옵니다.\n",
    "    train_images, test_images, train_labels, test_labels = preprocess()\n",
    "    \n",
    "    # 지시사항 2에서 설정한 모델을 불러옵니다.\n",
    "    model = CNN()\n",
    "    \n",
    "    # 모델의 구조를 확인합니다.\n",
    "    model.summary()\n",
    "    \n",
    "    # 컴파일러를 설정합니다. optimizer는 adam으로 해도 되고...\n",
    "    #optimizer = tf.keras.optimizers.Adam(0.0001) -> 이거 쓸거면 아래에 optimizer = optimizer 로 써줘야 함\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'sgd',metrics=['accuracy'] )\n",
    "    \n",
    "    # fit 함수를 사용하여 모델을 학습합니다.\n",
    "    # 학습 수행 시 정보는 history에 저장합니다.\n",
    "    history = model.fit(train_images, train_labels, epochs=2, batch_size=128, validation_data=(test_images, test_labels), verbose = 2 )\n",
    "    \n",
    "    # evaluate 함수를 사용하여 테스트 데이터의 결과값을 저장합니다.\n",
    "    loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "    \n",
    "    print('\\nTest Loss : {:.4f} | Test Accuracy : {}'.format(loss, test_acc))\n",
    "    print('예측한 Test Data 클래스 : ',model.predict_classes(test_images)[:10])\n",
    "    \n",
    "    Visulaize([('CNN', history)], 'loss')\n",
    "    \n",
    "    Plotter(test_images, model)\n",
    "    \n",
    "    return test_acc\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
